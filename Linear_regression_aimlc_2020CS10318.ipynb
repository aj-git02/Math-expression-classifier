{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age     sex     bmi  children smoker     region      charges\n",
      "0   19  female  27.900         0    yes  southwest  16884.92400\n",
      "1   18    male  33.770         1     no  southeast   1725.55230\n",
      "2   28    male  33.000         3     no  southeast   4449.46200\n",
      "3   33    male  22.705         0     no  northwest  21984.47061\n",
      "4   32    male  28.880         0     no  northwest   3866.85520\n",
      "1338\n",
      "7\n",
      "['age', 'sex', 'bmi', 'children', 'smoker', 'region', 'charges']\n",
      "count     1338.000000\n",
      "mean     13270.422265\n",
      "std      12110.011237\n",
      "min       1121.873900\n",
      "25%       4740.287150\n",
      "50%       9382.033000\n",
      "75%      16639.912515\n",
      "max      63770.428010\n",
      "Name: charges, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#the code has been written with the help of the following resources\n",
    "#https://github.com/AIMLC-IITD/Summer-of-ML-2021/blob/main/Week-1/Day-2/Practice-Assignment/02-insurance-linear.ipynb\n",
    "# for initial code and analysing data\n",
    "#https://github.com/anoopv511/COL-774-Assignments/blob/master/Assignment%201/Linear%20Regression.ipynb \n",
    "# for batch gradient descent\n",
    "\n",
    "#Akarsh Jain\n",
    "#2020CS10318\n",
    "#akarshjain02@gmail.com\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('insurance.csv')\n",
    "print(data.head())\n",
    "\n",
    "num_rows = len(data.index)\n",
    "print(num_rows)\n",
    "num_cols = len(data.columns)\n",
    "print(num_cols)\n",
    "input_cols = list(data.columns)\n",
    "print(input_cols)\n",
    "\n",
    "print(data[\"charges\"].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1338, 6)\n",
      "(1338, 1)\n"
     ]
    }
   ],
   "source": [
    "output_cols = [\"charges\"]\n",
    "categorical_cols = list(data.select_dtypes([\"object\"]).columns)\n",
    "\n",
    "for col in categorical_cols:\n",
    "    data[col] = data[col].astype('category').cat.codes\n",
    "\n",
    "x = data[input_cols].to_numpy()\n",
    "x=np.delete(x,6,1)\n",
    "\n",
    "y= data[output_cols].to_numpy()\n",
    "\n",
    "print(np.shape(x))\n",
    "print(np.shape(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [[ 0.38988873 -0.69926733  0.90007235 -0.69926733 -0.64194332 -0.52729532]\n",
      " [ 0.33256472 -0.64194332  1.23656425 -0.64194332 -0.69926733 -0.58461932]\n",
      " [ 0.90580475 -0.64194332  1.19242477 -0.52729532 -0.69926733 -0.58461932]\n",
      " ...\n",
      " [ 0.33256472 -0.69926733  1.41312218 -0.69926733 -0.69926733 -0.58461932]\n",
      " [ 0.50453673 -0.69926733  0.77969195 -0.69926733 -0.69926733 -0.52729532]\n",
      " [ 2.79749685 -0.69926733  0.96714144 -0.69926733 -0.64194332 -0.64194332]]\n",
      "y: [[1.27237277]\n",
      " [0.13002995]\n",
      " [0.33529167]\n",
      " ...\n",
      " [0.122817  ]\n",
      " [0.1513098 ]\n",
      " [2.1959633 ]]\n",
      "diff: [[1.27237277]\n",
      " [0.13002995]\n",
      " [0.33529167]\n",
      " ...\n",
      " [0.122817  ]\n",
      " [0.1513098 ]\n",
      " [2.1959633 ]]\n",
      "gradient: [[2365.36326143]\n",
      " [-894.86450488]\n",
      " [1500.84226512]\n",
      " [-845.90691398]\n",
      " [-897.68525834]\n",
      " [-819.84635324]]\n"
     ]
    }
   ],
   "source": [
    "x = (x - np.mean(x))/np.std(x)  #std(x)=1\n",
    "print(\"x:\",x)\n",
    "\n",
    "aux=np.mean(y)\n",
    "y=y/aux \n",
    "# value will be multiplied later so that other values do not get extremely large\n",
    "# 10000 estimated from mean of the output\n",
    "\n",
    "print(\"y:\",y)\n",
    "#testing\n",
    "\n",
    "theta = np.zeros((x.shape[1],1))\n",
    "theta_list = [theta]\n",
    "diff = y - x@theta\n",
    "print(\"diff:\",diff)\n",
    "print(\"gradient:\",x.T@diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  -  1225.6997408595914\n",
      "500  -  487.62361190692195\n",
      "1000  -  482.7186311765664\n",
      "1500  -  478.5115381432655\n",
      "2000  -  474.52809640909334\n",
      "2500  -  470.7223911605839\n",
      "3000  -  467.0800291998779\n",
      "3500  -  463.58983617960916\n",
      "4000  -  460.24174961202914\n",
      "4500  -  457.0265833215317\n",
      "5000  -  453.93593379850125\n",
      "Final Cost -  453.93593379850125\n",
      "parameters =  [[ 0.33697742 -0.70039125  0.54045624 -0.23893043  1.88353845 -0.93151315]]\n"
     ]
    }
   ],
   "source": [
    "def gradient_descent(x,y,eta,maxit,mincost):\n",
    "    theta = np.zeros((x.shape[1],1))\n",
    "    theta_list = [theta]\n",
    "    diff = y - x@theta\n",
    "    cost = 0.5*np.sum(diff**2)\n",
    "    cost_list = [cost]\n",
    "    iterations = 0\n",
    "    while(cost > mincost and iterations < maxit): \n",
    "        if (iterations % 500 == 0): print(iterations,\" - \",cost)\n",
    "        theta = theta + eta*(x.T@diff)\n",
    "        theta_list.append(theta)\n",
    "        diff = y - x@theta\n",
    "        cost = 0.5*np.sum(diff**2)\n",
    "        cost_list.append(cost)\n",
    "        iterations += 1\n",
    "    print(iterations,\" - \",cost)\n",
    "    print(\"Final Cost - \",cost)\n",
    "    print(\"parameters = \",theta.T)\n",
    "    return theta_list, cost_list\n",
    "    \n",
    "theta_list, cost_list = gradient_descent(x,y,0.00002675,5000,10)\n",
    "\n",
    "#alogrithm is clearly diverging for eta=0.000268"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters: [[  0.34741867 -10.63186741   0.67122089  -1.11214562  14.25094247\n",
      "   -2.77771136]]\n",
      "cost: 341.4717221076601\n"
     ]
    }
   ],
   "source": [
    "#implementing a direct method of linear regression (normal equation)\n",
    "\n",
    "alpha=np.linalg.inv(x.T@x)\n",
    "beta=x.T@y\n",
    "theta_new=alpha@beta\n",
    "print(\"parameters:\",theta_new.T)\n",
    "\n",
    "#finding the cost\n",
    "diff = y - x@theta_new\n",
    "cost = 0.5*np.sum(diff**2)\n",
    "print(\"cost:\",cost)\n",
    "\n",
    "#hence it can be said that the final cost after batch gradient descent is comparable to the best mathematical linear fit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
